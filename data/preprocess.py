"""
TODO:

Clean the text (remove unwanted characters, normalize)
- Use tokenizer to convert text to token IDs
- Split dataset into train and val sets
- Save token ID datasets as binary or torch tensors (e.g., train.bin)


"""